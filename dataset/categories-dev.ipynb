{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download llama model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 22 key-value pairs and 291 tensors from llm_cache/models--QuantFactory--Meta-Llama-3-8B-Instruct-GGUF/snapshots/33b3a2a0f06a820b6306ab3aa2020ecb6bcf22da/./Meta-Llama-3-8B-Instruct.Q6_K.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = models\n",
      "llama_model_loader: - kv   2:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   3:                       llama.context_length u32              = 8192\n",
      "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   7:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   8:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 18\n",
      "llama_model_loader: - kv  11:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  12:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  14:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  15:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  16:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  17:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 128001\n",
      "llama_model_loader: - kv  20:                    tokenizer.chat_template str              = {% set loop_messages = messages %}{% ...\n",
      "llama_model_loader: - kv  21:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q6_K:  226 tensors\n",
      "llm_load_vocab: special tokens cache size = 256\n",
      "llm_load_vocab: token to piece cache size = 0.8000 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 128256\n",
      "llm_load_print_meta: n_merges         = 280147\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 8192\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 500000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 8192\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 8B\n",
      "llm_load_print_meta: model ftype      = Q6_K\n",
      "llm_load_print_meta: model params     = 8.03 B\n",
      "llm_load_print_meta: model size       = 6.14 GiB (6.56 BPW) \n",
      "llm_load_print_meta: general.name     = models\n",
      "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
      "llm_load_print_meta: EOS token        = 128001 '<|end_of_text|>'\n",
      "llm_load_print_meta: LF token         = 128 'Ä'\n",
      "llm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: max token length = 256\n",
      "llm_load_tensors: ggml ctx size =    0.14 MiB\n",
      "llm_load_tensors:        CPU buffer size =  6282.97 MiB\n",
      ".........................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 500000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =    64.00 MiB\n",
      "llama_new_context_with_model: KV self size  =   64.00 MiB, K (f16):   32.00 MiB, V (f16):   32.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.49 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   258.50 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 1 | AVX512_VNNI = 1 | AVX512_BF16 = 1 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'tokenizer.chat_template': \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\", 'tokenizer.ggml.eos_token_id': '128001', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '8192', 'general.name': 'models', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.file_type': '18', 'llama.vocab_size': '128256', 'llama.rope.dimension_count': '128'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Guessed chat format: llama-3\n",
      "\n",
      "llama_print_timings:        load time =     543.89 ms\n",
      "llama_print_timings:      sample time =       0.30 ms /     8 runs   (    0.04 ms per token, 26402.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     543.87 ms /    17 tokens (   31.99 ms per token,    31.26 tokens per second)\n",
      "llama_print_timings:        eval time =     777.29 ms /     7 runs   (  111.04 ms per token,     9.01 tokens per second)\n",
      "llama_print_timings:       total time =    1324.98 ms /    24 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-6048bd52-5974-4d41-bc51-3dbbe8a2b9eb',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1724256030,\n",
       " 'model': 'llm_cache/models--QuantFactory--Meta-Llama-3-8B-Instruct-GGUF/snapshots/33b3a2a0f06a820b6306ab3aa2020ecb6bcf22da/./Meta-Llama-3-8B-Instruct.Q6_K.gguf',\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': 'The capital of France is Paris.'},\n",
       "   'logprobs': None,\n",
       "   'finish_reason': 'stop'}],\n",
       " 'usage': {'prompt_tokens': 17, 'completion_tokens': 7, 'total_tokens': 24}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "llm = Llama.from_pretrained(\n",
    "    repo_id=\"QuantFactory/Meta-Llama-3-8B-Instruct-GGUF\",\n",
    "    filename=\"Meta-Llama-3-8B-Instruct.Q6_K.gguf\",\n",
    "    cache_dir=\"llm_cache\",\n",
    ")\n",
    "\n",
    "llm.create_chat_completion(\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is the capital of France?\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Guidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from guidance import models, gen, select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a model (could be Transformers, LlamaCpp, VertexAI, OpenAI...)\n",
    "lm = models.LlamaCpp(\n",
    "    \"llm_cache/models--QuantFactory--Meta-Llama-3-8B-Instruct-GGUF/snapshots/33b3a2a0f06a820b6306ab3aa2020ecb6bcf22da/Meta-Llama-3-8B-Instruct.Q6_K.gguf\",\n",
    "    n_gpu_layers=-1,\n",
    "    n_ctx=4096,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"This product: {product}\\n\\n is best categorized as: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 0px; padding: 0px; vertical-align: middle; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'>This product: toilet brush\n",
       "\n",
       " is best categorized as: <span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>home</span></pre>"
      ],
      "text/plain": [
       "<guidance.models.llama_cpp._llama_cpp.LlamaCpp at 0x78eac0d79f00>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    lm\n",
    "    + prompt.format(product=\"toilet brush\")\n",
    "    + select(\n",
    "        [\"sports equipment\", \"home\", \"food\", \"electronics\", \"art\"], name=\"category\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on known products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\n",
    "    \"c4-raw-meta-filtered_2024-Aug-20_20-44-50/sampled_item_metadata_1M_filtered.jsonl\",\n",
    "    lines=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(100).to_csv(\"test_categories_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"test_categories_sample.csv\", index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = df[\"file_name\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Home & Kitchen',\n",
       " 'Health & Household',\n",
       " 'Clothing Shoes & Jewelry',\n",
       " 'Tools & Home Improvement',\n",
       " 'Books',\n",
       " 'Toys & Games',\n",
       " 'Beauty & Personal Care',\n",
       " 'Electronics',\n",
       " 'Pet Supplies',\n",
       " 'Grocery & Gourmet Food',\n",
       " 'Arts Crafts & Sewing',\n",
       " 'Sports & Outdoors',\n",
       " 'Automotive',\n",
       " 'Office Products',\n",
       " 'Patio Lawn & Garden']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>376666</th>\n",
       "      <td>B0073RM9PC</td>\n",
       "      <td>Focus Foodservice Commercial Bakeware 17 by 25...</td>\n",
       "      <td>Focus Foodservice LLC is committed to providin...</td>\n",
       "      <td>Home &amp; Kitchen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761113</th>\n",
       "      <td>B0BPXBGP61</td>\n",
       "      <td>Sanrio Kuromi Lighter, Kawaii Hello Kitty Anim...</td>\n",
       "      <td>❗️PLEASE NOTE: Due to strict transportation re...</td>\n",
       "      <td>Health &amp; Household</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174091</th>\n",
       "      <td>B000I0UW0K</td>\n",
       "      <td>Pleaser Women's 7 inch Sandal (Black/Glitter;7)</td>\n",
       "      <td>TIPJAR-709-5\\n7\" Heel\\nSize: 5-14\\n7\" (178mm) ...</td>\n",
       "      <td>Clothing Shoes &amp; Jewelry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460099</th>\n",
       "      <td>B00ECJ8JBM</td>\n",
       "      <td>Sanrio Hello Kitty Blackout Window Panel Drape...</td>\n",
       "      <td>Sanrio Hello Kitty Blackout Window Panel Drape...</td>\n",
       "      <td>Home &amp; Kitchen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666812</th>\n",
       "      <td>B0141PFHY8</td>\n",
       "      <td>3dRose lsp_217993_1 Gold Butterflies and Flour...</td>\n",
       "      <td>Gold butterflies and flourishes on a two-tone ...</td>\n",
       "      <td>Tools &amp; Home Improvement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           item_id                                              title  \\\n",
       "376666  B0073RM9PC  Focus Foodservice Commercial Bakeware 17 by 25...   \n",
       "761113  B0BPXBGP61  Sanrio Kuromi Lighter, Kawaii Hello Kitty Anim...   \n",
       "174091  B000I0UW0K    Pleaser Women's 7 inch Sandal (Black/Glitter;7)   \n",
       "460099  B00ECJ8JBM  Sanrio Hello Kitty Blackout Window Panel Drape...   \n",
       "666812  B0141PFHY8  3dRose lsp_217993_1 Gold Butterflies and Flour...   \n",
       "\n",
       "                                              description  \\\n",
       "376666  Focus Foodservice LLC is committed to providin...   \n",
       "761113  ❗️PLEASE NOTE: Due to strict transportation re...   \n",
       "174091  TIPJAR-709-5\\n7\" Heel\\nSize: 5-14\\n7\" (178mm) ...   \n",
       "460099  Sanrio Hello Kitty Blackout Window Panel Drape...   \n",
       "666812  Gold butterflies and flourishes on a two-tone ...   \n",
       "\n",
       "                       file_name  \n",
       "376666            Home & Kitchen  \n",
       "761113        Health & Household  \n",
       "174091  Clothing Shoes & Jewelry  \n",
       "460099            Home & Kitchen  \n",
       "666812  Tools & Home Improvement  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are an AI model trained to assist in categorizing products in an e-commerce dataset. \n",
    "Your task is to assign the most appropriate category to each product based on its description, title, and other available attributes. \n",
    "Follow these guidelines:\n",
    "\n",
    "Understand the Product:\n",
    "\n",
    "Carefully read the product's title, description, and any additional details (e.g., brand, material, color).\n",
    "Consider the primary use or function of the product.\n",
    "Select the Most Accurate Category:\n",
    "\n",
    "Choose the category that best matches the product's main purpose.\n",
    "If a product could fit into multiple categories, prioritize the category that a typical customer would most likely search under.\n",
    "Handle Ambiguities:\n",
    "\n",
    "If the product information is vague or incomplete, select the category that seems most appropriate based on the available details.\n",
    "If a product fits equally into two categories, choose the broader or more general category.\n",
    "Consistency:\n",
    "\n",
    "Apply the same reasoning across similar products to ensure consistency in categorization.\n",
    "Special Considerations:\n",
    "\n",
    "Be mindful of products that may have specific subcategories (e.g., electronics, apparel, home goods).\n",
    "Consider seasonal or contextual relevance (e.g., holiday decorations vs. home decor).\n",
    "\n",
    "This product: {product}\\n\\n is best categorized as: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 0px; padding: 0px; vertical-align: middle; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'>\n",
       "You are an AI model trained to assist in categorizing products in an e-commerce dataset. \n",
       "Your task is to assign the most appropriate category to each product based on its description, title, and other available attributes. \n",
       "Follow these guidelines:\n",
       "\n",
       "Understand the Product:\n",
       "\n",
       "Carefully read the product&#x27;s title, description, and any additional details (e.g., brand, material, color).\n",
       "Consider the primary use or function of the product.\n",
       "Select the Most Accurate Category:\n",
       "\n",
       "Choose the category that best matches the product&#x27;s main purpose.\n",
       "If a product could fit into multiple categories, prioritize the category that a typical customer would most likely search under.\n",
       "Handle Ambiguities:\n",
       "\n",
       "If the product information is vague or incomplete, select the category that seems most appropriate based on the available details.\n",
       "If a product fits equally into two categories, choose the broader or more general category.\n",
       "Consistency:\n",
       "\n",
       "Apply the same reasoning across similar products to ensure consistency in categorization.\n",
       "Special Considerations:\n",
       "\n",
       "Be mindful of products that may have specific subcategories (e.g., electronics, apparel, home goods).\n",
       "Consider seasonal or contextual relevance (e.g., holiday decorations vs. home decor).\n",
       "\n",
       "This product: Focus Foodservice Commercial Bakeware 17 by 25-Inch Chrome Plated Cooling Grate\n",
       "Focus Foodservice LLC is committed to providing the foodservice industry with products and services that provide exceptional value and create operational efficiency. Our team of foodservice professionals works to provide solutions in the foodservice industry. Our Focus Foodservice commercial bakeware pans are manufactured to meet the exacting standards of the toughest commercial bakeries and foodservice establishments. This commercial chrome plated heavy gauge steel grate features 2 welded support rods for greater rigidity. It fits into a standard full size sheet pan and measures 17&quot; x 25&quot;.\n",
       "\n",
       " is best categorized as: <span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>Home</span> &amp; Kitchen</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home & Kitchen\n"
     ]
    }
   ],
   "source": [
    "index = 376666\n",
    "out = (\n",
    "    lm\n",
    "    + prompt.format(product=\"\\n\".join([df[\"title\"][index], df[\"description\"][index]]))\n",
    "    + select(categories, name=\"category\")\n",
    ")[\"category\"]\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category(title: str, description: str):\n",
    "    CATEGORIES = [\n",
    "        \"Home & Kitchen\",\n",
    "        \"Health & Household\",\n",
    "        \"Clothing Shoes & Jewelry\",\n",
    "        \"Tools & Home Improvement\",\n",
    "        \"Books\",\n",
    "        \"Toys & Games\",\n",
    "        \"Beauty & Personal Care\",\n",
    "        \"Electronics\",\n",
    "        \"Pet Supplies\",\n",
    "        \"Grocery & Gourmet Food\",\n",
    "        \"Arts Crafts & Sewing\",\n",
    "        \"Sports & Outdoors\",\n",
    "        \"Automotive\",\n",
    "        \"Office Products\",\n",
    "        \"Patio Lawn & Garden\",\n",
    "    ]\n",
    "    return (\n",
    "        lm\n",
    "        + prompt.format(product=\"\\n\".join([title, description]))\n",
    "        + select(CATEGORIES, name=\"category\")\n",
    "    )[\"category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 0px; padding: 0px; vertical-align: middle; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'>This product: SHUOXI 4-Pack Double Bangs Hair Clips Hairpins for Little Girls Flower Hair Clips For Girl Hairpins Clip (Comb1)\n",
       "Lazy double bangs hairpins, side clips, duckbill clips, styling clips. 1.Girls flower side clips with double-layer hairpin design, the bottom layer is a large toothed duckbill rack with 3 small clips with sweet patterns on it. 2.This side hair clip is simple to use, stylish and beautiful, suitable for all girls and young ladies. 3.The side hair clips are made of high-quality resin, and the workmanship is smooth and round without hurting the hair. 4.This is an excellent gift for girls. Easily create stylish and simple hairstyles for Girls women. 5. One package include 4 different flower hair clips.\n",
       "\n",
       " is best categorized as: <span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>Beauty</span> &amp; Personal Care</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = []\n",
    "for index, item_id, title, description, file_name in tqdm(\n",
    "    df.itertuples(), total=len(df)\n",
    "):\n",
    "    predicted_category = get_category(title, description)\n",
    "    results.append(\n",
    "        {\"item_id\": item_id, \"expected\": file_name, \"predicted\": predicted_category}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"category\"] = [result[\"predicted\"] for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"prediction\"] = df[\"category\"] == df[\"file_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prediction\n",
       "True     34\n",
       "False    26\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"prediction\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prediction\n",
    "True     38\n",
    "False    22\n",
    "Name: count, dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>file_name</th>\n",
       "      <th>category</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>376666</th>\n",
       "      <td>B0073RM9PC</td>\n",
       "      <td>Focus Foodservice Commercial Bakeware 17 by 25...</td>\n",
       "      <td>Focus Foodservice LLC is committed to providin...</td>\n",
       "      <td>Home &amp; Kitchen</td>\n",
       "      <td>Home &amp; Kitchen</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761113</th>\n",
       "      <td>B0BPXBGP61</td>\n",
       "      <td>Sanrio Kuromi Lighter, Kawaii Hello Kitty Anim...</td>\n",
       "      <td>❗️PLEASE NOTE: Due to strict transportation re...</td>\n",
       "      <td>Health &amp; Household</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174091</th>\n",
       "      <td>B000I0UW0K</td>\n",
       "      <td>Pleaser Women's 7 inch Sandal (Black/Glitter;7)</td>\n",
       "      <td>TIPJAR-709-5\\n7\" Heel\\nSize: 5-14\\n7\" (178mm) ...</td>\n",
       "      <td>Clothing Shoes &amp; Jewelry</td>\n",
       "      <td>Clothing Shoes &amp; Jewelry</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460099</th>\n",
       "      <td>B00ECJ8JBM</td>\n",
       "      <td>Sanrio Hello Kitty Blackout Window Panel Drape...</td>\n",
       "      <td>Sanrio Hello Kitty Blackout Window Panel Drape...</td>\n",
       "      <td>Home &amp; Kitchen</td>\n",
       "      <td>Home &amp; Kitchen</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666812</th>\n",
       "      <td>B0141PFHY8</td>\n",
       "      <td>3dRose lsp_217993_1 Gold Butterflies and Flour...</td>\n",
       "      <td>Gold butterflies and flourishes on a two-tone ...</td>\n",
       "      <td>Tools &amp; Home Improvement</td>\n",
       "      <td>Home &amp; Kitchen</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           item_id                                              title  \\\n",
       "376666  B0073RM9PC  Focus Foodservice Commercial Bakeware 17 by 25...   \n",
       "761113  B0BPXBGP61  Sanrio Kuromi Lighter, Kawaii Hello Kitty Anim...   \n",
       "174091  B000I0UW0K    Pleaser Women's 7 inch Sandal (Black/Glitter;7)   \n",
       "460099  B00ECJ8JBM  Sanrio Hello Kitty Blackout Window Panel Drape...   \n",
       "666812  B0141PFHY8  3dRose lsp_217993_1 Gold Butterflies and Flour...   \n",
       "\n",
       "                                              description  \\\n",
       "376666  Focus Foodservice LLC is committed to providin...   \n",
       "761113  ❗️PLEASE NOTE: Due to strict transportation re...   \n",
       "174091  TIPJAR-709-5\\n7\" Heel\\nSize: 5-14\\n7\" (178mm) ...   \n",
       "460099  Sanrio Hello Kitty Blackout Window Panel Drape...   \n",
       "666812  Gold butterflies and flourishes on a two-tone ...   \n",
       "\n",
       "                       file_name                  category  prediction  \n",
       "376666            Home & Kitchen            Home & Kitchen        True  \n",
       "761113        Health & Household               Electronics       False  \n",
       "174091  Clothing Shoes & Jewelry  Clothing Shoes & Jewelry        True  \n",
       "460099            Home & Kitchen            Home & Kitchen        True  \n",
       "666812  Tools & Home Improvement            Home & Kitchen       False  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check these manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClimaTek Upgraded Furnace Blower Motor fits Rheem 51-22858-01\n",
      "This is a brand new ClimaTek Furnace Blower Motor\n",
      "expected: Tools & Home Improvement\n",
      "predicted Home & Kitchen\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected:\u001b[39m\u001b[38;5;124m\"\u001b[39m, entry[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_name\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicted\u001b[39m\u001b[38;5;124m\"\u001b[39m, entry[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m clear_output(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/dev/ECS/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/ECS/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "wrong_ones = df[df[\"prediction\"] == False]\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "for index, entry in wrong_ones.drop(columns=[\"prediction\"]).iterrows():\n",
    "    print(entry[\"title\"])\n",
    "    print(entry[\"description\"])\n",
    "    print(\"expected:\", entry[\"file_name\"])\n",
    "    print(\"predicted\", entry[\"category\"])\n",
    "    input()\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'expected': 'Home & Kitchen', 'predicted': 'Toys & Games'},\n",
       " {'expected': 'Movies & TV', 'predicted': 'Sports & Outdoors'},\n",
       " {'expected': 'Health & Household', 'predicted': 'Health & Household'},\n",
       " {'expected': 'Clothing Shoes & Jewelry', 'predicted': 'Books'},\n",
       " {'expected': 'Clothing Shoes & Jewelry',\n",
       "  'predicted': 'Clothing Shoes & Jewelry'},\n",
       " {'expected': 'Health & Household', 'predicted': 'Health & Household'},\n",
       " {'expected': 'Beauty & Personal Care', 'predicted': 'Beauty & Personal Care'},\n",
       " {'expected': 'Office Products', 'predicted': 'Home & Kitchen'},\n",
       " {'expected': 'Grocery & Gourmet Food',\n",
       "  'predicted': 'Clothing Shoes & Jewelry'},\n",
       " {'expected': 'Pet Supplies', 'predicted': 'Pet Supplies'},\n",
       " {'expected': 'Pet Supplies', 'predicted': 'Pet Supplies'},\n",
       " {'expected': 'Tools & Home Improvement', 'predicted': 'Home & Kitchen'},\n",
       " {'expected': 'Home & Kitchen', 'predicted': 'Home & Kitchen'},\n",
       " {'expected': 'Baby Products', 'predicted': 'Baby Products'},\n",
       " {'expected': 'Home & Kitchen', 'predicted': 'Tools & Home Improvement'},\n",
       " {'expected': 'Sports & Outdoors', 'predicted': 'Sports & Outdoors'},\n",
       " {'expected': 'Tools & Home Improvement',\n",
       "  'predicted': 'Tools & Home Improvement'},\n",
       " {'expected': 'Clothing Shoes & Jewelry',\n",
       "  'predicted': 'Clothing Shoes & Jewelry'},\n",
       " {'expected': 'Clothing Shoes & Jewelry',\n",
       "  'predicted': 'Clothing Shoes & Jewelry'},\n",
       " {'expected': 'Sports & Outdoors', 'predicted': 'Toys & Games'},\n",
       " {'expected': 'Clothing Shoes & Jewelry',\n",
       "  'predicted': 'Clothing Shoes & Jewelry'},\n",
       " {'expected': 'Toys & Games', 'predicted': 'Toys & Games'},\n",
       " {'expected': 'Sports & Outdoors', 'predicted': 'Books'},\n",
       " {'expected': 'Home & Kitchen', 'predicted': 'Home & Kitchen'},\n",
       " {'expected': 'Kindle Store', 'predicted': 'Books'},\n",
       " {'expected': 'Baby Products', 'predicted': 'Home & Kitchen'},\n",
       " {'expected': 'Health & Household', 'predicted': 'Toys & Games'}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_correct = list(map(lambda x: x[\"expected\"] == x[\"predicted\"], results)).count(True)\n",
    "n_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
