{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "from pathlib import Path\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Tuple\n",
    "from loguru import logger\n",
    "import yaml\n",
    "from utils import OpenAIConfig\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"gpt-4o\",\n",
    "    \"gpt-4o-mini\",\n",
    "    \"gpt-3.5-turbo\",\n",
    "    \"text-embedding-3-large\",\n",
    "    \"text-embedding-3-small\",\n",
    "    \"text-embedding-ada-002\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-4o': 'o200k_base',\n",
       " 'gpt-4o-mini': 'o200k_base',\n",
       " 'gpt-3.5-turbo': 'cl100k_base',\n",
       " 'text-embedding-3-large': 'cl100k_base',\n",
       " 'text-embedding-3-small': 'cl100k_base',\n",
       " 'text-embedding-ada-002': 'cl100k_base'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{model: tiktoken.encoding_name_for_model(model_name=model) for model in models}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = Path(\"./config.yaml\")\n",
    "assert config_path.exists(), f\"File not found {config_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_config = OpenAIConfig.load_config_yaml(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAIConfig(url=URLConfig(embedding='https://api.openai.com/v1/embeddings',\n",
      "                           chat='https://api.openai.com/v1/chat/completions'),\n",
      "             max_attempts=5,\n",
      "             logging_level=20,\n",
      "             limits=LimitsConfig(requests_per_minute={'gpt_3_5_turbo': 3500,\n",
      "                                                      'gpt_4o': 500,\n",
      "                                                      'gpt_4o_mini': 500,\n",
      "                                                      'text_embedding_3_large': 3000,\n",
      "                                                      'text_embedding_3_small': 3000,\n",
      "                                                      'text_embedding_ada_002': 3000},\n",
      "                                 tokens_per_minute={'gpt_3_5_turbo': 200000,\n",
      "                                                    'gpt_4o': 30000,\n",
      "                                                    'gpt_4o_mini': 200000,\n",
      "                                                    'text_embedding_3_large': 1000000,\n",
      "                                                    'text_embedding_3_small': 1000000,\n",
      "                                                    'text_embedding_ada_002': 1000000}),\n",
      "             token_encoding=TokenEncodingConfig(gpt_4o='o200k_base',\n",
      "                                                gpt_4o_mini='o200k_base',\n",
      "                                                gpt_3_5_turbo='cl100k_base',\n",
      "                                                text_embedding_3_large='cl100k_base',\n",
      "                                                text_embedding_3_small='cl100k_base',\n",
      "                                                text_embedding_ada_002='cl100k_base'))\n"
     ]
    }
   ],
   "source": [
    "pprint(openai_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests_file = Path(\"./requests_to_parallel_process.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_requests = 10\n",
    "jobs = [\n",
    "    {\n",
    "        \"model\": \"text-embedding-3-small\",\n",
    "        \"input\": str(x) + \"\\n\",\n",
    "        \"metadata\": {\"id\": x},\n",
    "    }\n",
    "    for x in range(n_requests)\n",
    "]\n",
    "with open(requests_file, \"w\") as f:\n",
    "    for job in jobs:\n",
    "        json_string = json.dumps(job)\n",
    "        f.write(json_string + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_jsonl(jobs: List[Dict], file_path: Path) -> None:\n",
    "    with open(file_path, \"w\") as f:\n",
    "        for job in jobs:\n",
    "            json_string = json.dumps(job)\n",
    "            f.write(json_string + \"\\n\")\n",
    "\n",
    "\n",
    "def create_jobs(\n",
    "    df: pd.DataFrame,\n",
    "    model: str,\n",
    "    file_path: Path,\n",
    "    product_key: str = \"product_text\",\n",
    "    id_key: str = \"id\",\n",
    ") -> None:\n",
    "\n",
    "    assert file_path.suffix == \".jsonl\", ValueError(\"File path must be a JSONL file!\")\n",
    "\n",
    "    jobs = [\n",
    "        {\n",
    "            \"model\": model,\n",
    "            \"input\": getattr(row, product_key),\n",
    "            \"metadata\": {id_key: getattr(row, id_key)},\n",
    "        }\n",
    "        for row in df.itertuples()\n",
    "    ]\n",
    "    save_jsonl(jobs=jobs, file_path=file_path)\n",
    "\n",
    "\n",
    "def load_results(results_path: Path) -> Tuple[pd.DataFrame, List[str]]:\n",
    "    \"\"\"\n",
    "    Load results from a JSONL file and return a DataFrame.\n",
    "    \"\"\"\n",
    "    assert results_path.exists(), FileNotFoundError(\"There is no results file!\")\n",
    "    assert results_path.suffix == \".jsonl\", ValueError(\n",
    "        \"File path must be a JSONL file!\"\n",
    "    )\n",
    "\n",
    "    embeddings = []\n",
    "    fail_ids = []\n",
    "    with open(results_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                embedding = data[1][\"data\"][0][\"embedding\"]\n",
    "                id = data[2][\"id\"]\n",
    "                embeddings.append({\"id\": id, \"embeddings\": embedding})\n",
    "            except Exception as e:\n",
    "                fail_ids.append(id)\n",
    "                logger.warning(f\"JSON loads failed for ID: {id}, with exception: {e}\")\n",
    "\n",
    "    df = pd.DataFrame(embeddings)\n",
    "    return df, fail_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminal command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "python dataset/api_request_parallel_processor.py \\\n",
    "  --requests_filepath dataset/example_requests_to_parallel_process.jsonl \\\n",
    "  --save_filepath examples/data/example_requests_to_parallel_process_results.jsonl \\\n",
    "  --request_url https://api.openai.com/v1/embeddings \\\n",
    "  --max_requests_per_minute 1500 \\\n",
    "  --max_tokens_per_minute 6250000 \\\n",
    "  --token_encoding_name cl100k_base \\\n",
    "  --max_attempts 5 \\\n",
    "  --logging_level 20\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
