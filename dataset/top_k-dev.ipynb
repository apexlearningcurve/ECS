{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import yaml\n",
    "from loguru import logger\n",
    "from openai import OpenAI\n",
    "from utils import OpenAIConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"gpt-4o\",\n",
    "    \"gpt-4o-mini\",\n",
    "    \"gpt-3.5-turbo\",\n",
    "    \"text-embedding-3-large\",\n",
    "    \"text-embedding-3-small\",\n",
    "    \"text-embedding-ada-002\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-4o': 'o200k_base',\n",
       " 'gpt-4o-mini': 'o200k_base',\n",
       " 'gpt-3.5-turbo': 'cl100k_base',\n",
       " 'text-embedding-3-large': 'cl100k_base',\n",
       " 'text-embedding-3-small': 'cl100k_base',\n",
       " 'text-embedding-ada-002': 'cl100k_base'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{model: tiktoken.encoding_name_for_model(model_name=model) for model in models}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = Path(\"./config.yaml\")\n",
    "assert config_path.exists(), f\"File not found {config_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_config = OpenAIConfig.load_config_yaml(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAIConfig(url=URLConfig(embedding='https://api.openai.com/v1/embeddings',\n",
      "                           chat='https://api.openai.com/v1/chat/completions'),\n",
      "             max_attempts=5,\n",
      "             logging_level=20,\n",
      "             limits=LimitsConfig(requests_per_minute={'gpt_3_5_turbo': 3500,\n",
      "                                                      'gpt_4o': 500,\n",
      "                                                      'gpt_4o_mini': 500,\n",
      "                                                      'text_embedding_3_large': 3000,\n",
      "                                                      'text_embedding_3_small': 3000,\n",
      "                                                      'text_embedding_ada_002': 3000},\n",
      "                                 tokens_per_minute={'gpt_3_5_turbo': 200000,\n",
      "                                                    'gpt_4o': 30000,\n",
      "                                                    'gpt_4o_mini': 200000,\n",
      "                                                    'text_embedding_3_large': 1000000,\n",
      "                                                    'text_embedding_3_small': 1000000,\n",
      "                                                    'text_embedding_ada_002': 1000000}),\n",
      "             token_encoding=TokenEncodingConfig(gpt_4o='o200k_base',\n",
      "                                                gpt_4o_mini='o200k_base',\n",
      "                                                gpt_3_5_turbo='cl100k_base',\n",
      "                                                text_embedding_3_large='cl100k_base',\n",
      "                                                text_embedding_3_small='cl100k_base',\n",
      "                                                text_embedding_ada_002='cl100k_base'))\n"
     ]
    }
   ],
   "source": [
    "pprint(openai_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests_file = Path(\"./requests_to_parallel_process.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_requests = 10\n",
    "jobs = [\n",
    "    {\n",
    "        \"model\": \"text-embedding-3-small\",\n",
    "        \"input\": str(x) + \"\\n\",\n",
    "        \"metadata\": {\"id\": x},\n",
    "    }\n",
    "    for x in range(n_requests)\n",
    "]\n",
    "with open(requests_file, \"w\") as f:\n",
    "    for job in jobs:\n",
    "        json_string = json.dumps(job)\n",
    "        f.write(json_string + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_jsonl(jobs: List[Dict], file_path: Path) -> None:\n",
    "    with open(file_path, \"w\") as f:\n",
    "        for job in jobs:\n",
    "            json_string = json.dumps(job)\n",
    "            f.write(json_string + \"\\n\")\n",
    "\n",
    "\n",
    "def create_jobs(\n",
    "    df: pd.DataFrame,\n",
    "    model: str,\n",
    "    file_path: Path,\n",
    "    product_key: str = \"product_text\",\n",
    "    id_key: str = \"id\",\n",
    ") -> None:\n",
    "\n",
    "    assert file_path.suffix == \".jsonl\", ValueError(\"File path must be a JSONL file!\")\n",
    "\n",
    "    jobs = [\n",
    "        {\n",
    "            \"model\": model,\n",
    "            \"input\": getattr(row, product_key),\n",
    "            \"metadata\": {id_key: getattr(row, id_key)},\n",
    "        }\n",
    "        for row in df.itertuples()\n",
    "    ]\n",
    "    save_jsonl(jobs=jobs, file_path=file_path)\n",
    "\n",
    "\n",
    "def load_results(results_path: Path) -> Tuple[pd.DataFrame, List[str]]:\n",
    "    \"\"\"\n",
    "    Load results from a JSONL file and return a DataFrame.\n",
    "    \"\"\"\n",
    "    assert results_path.exists(), FileNotFoundError(\"There is no results file!\")\n",
    "    assert results_path.suffix == \".jsonl\", ValueError(\n",
    "        \"File path must be a JSONL file!\"\n",
    "    )\n",
    "\n",
    "    embeddings = []\n",
    "    fail_ids = []\n",
    "    with open(results_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                embedding = data[1][\"data\"][0][\"embedding\"]\n",
    "                id = data[2][\"id\"]\n",
    "                embeddings.append({\"id\": id, \"embeddings\": embedding})\n",
    "            except Exception as e:\n",
    "                fail_ids.append(id)\n",
    "                logger.warning(f\"JSON loads failed for ID: {id}, with exception: {e}\")\n",
    "\n",
    "    df = pd.DataFrame(embeddings)\n",
    "    return df, fail_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminal command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "python dataset/api_request_parallel_processor.py \\\n",
    "  --requests_filepath dataset/example_requests_to_parallel_process.jsonl \\\n",
    "  --save_filepath examples/data/example_requests_to_parallel_process_results.jsonl \\\n",
    "  --request_url https://api.openai.com/v1/embeddings \\\n",
    "  --max_requests_per_minute 1500 \\\n",
    "  --max_tokens_per_minute 6250000 \\\n",
    "  --token_encoding_name cl100k_base \\\n",
    "  --max_attempts 5 \\\n",
    "  --logging_level 20\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Top K With Faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embeddings from JSONL file\n",
    "def load_embeddings(jsonl_file: Path, id_key: str = \"id\") -> np.ndarray:\n",
    "    embeddings = []\n",
    "    fail_ids = []\n",
    "    with open(jsonl_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            id = None  # Initialize id before the try block\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                id = data[2][id_key]\n",
    "                embedding = data[1][\"data\"][0][\"embedding\"]\n",
    "                embeddings.append(embedding)\n",
    "            except Exception as e:\n",
    "                if id is not None:\n",
    "                    fail_ids.append(id)\n",
    "                logger.warning(f\"JSON loads failed for ID: {id}, with exception: {e}\")\n",
    "\n",
    "    return np.array(embeddings).astype(\n",
    "        \"float32\"\n",
    "    )  # Convert to NumPy array of type float32\n",
    "\n",
    "\n",
    "jsonl_file = Path(\"your_embeddings_file.jsonl\")\n",
    "embeddings = load_embeddings(jsonl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the FAISS index\n",
    "dimension = embeddings.shape[1]  # Length of each vector\n",
    "index = faiss.IndexFlatL2(dimension)  # Use L2 distance (Euclidean)\n",
    "\n",
    "# Add the embeddings to the index\n",
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 100  # Number of nearest neighbors\n",
    "\n",
    "# Perform the search\n",
    "distances, indices = index.search(embeddings, k)\n",
    "\n",
    "# distances: 2D array of shape (number of queries, k) containing distances\n",
    "# indices: 2D array of shape (number of queries, k) containing indices of the nearest neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not run this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Save the results in a DataFrame\n",
    "df_results = pd.DataFrame(\n",
    "    {\n",
    "        \"query_index\": np.repeat(np.arange(len(embeddings)), k),\n",
    "        \"neighbor_index\": indices.flatten(),\n",
    "        \"distance\": distances.flatten(),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Optionally, save the DataFrame to a file\n",
    "df_results.to_csv(\"faiss_search_results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
