{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from datasets import Dataset\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "marqo_full_dir = Path(\"~/Datasets/marqo-gs-dataset/marqo_gs_full_10m\").expanduser()\n",
    "if not marqo_full_dir.exists():\n",
    "    raise FileExistsError(f\"Missing dataset file on location: {marqo_full_dir}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in dataset dir: 18\n",
      "Files in dataset dir:\n",
      "['corpus_1.json',\n",
      " 'corpus_2.json',\n",
      " 'query_0_product_id_0.csv',\n",
      " 'query_0_product_id_0_gt_dev.json',\n",
      " 'query_0_product_id_0_gt_test.json',\n",
      " 'query_0_product_id_0_queries.json',\n",
      " 'query_0_product_id_1.csv',\n",
      " 'query_0_product_id_1_gt_dev.json',\n",
      " 'query_0_product_id_1_gt_test.json',\n",
      " 'query_0_product_id_1_queries.json',\n",
      " 'query_1_product_id_0.csv',\n",
      " 'query_1_product_id_0_gt_dev.json',\n",
      " 'query_1_product_id_0_gt_test.json',\n",
      " 'query_1_product_id_0_queries.json',\n",
      " 'query_1_product_id_1.csv',\n",
      " 'query_1_product_id_1_gt_dev.json',\n",
      " 'query_1_product_id_1_gt_test.json',\n",
      " 'query_1_product_id_1_queries.json']\n"
     ]
    }
   ],
   "source": [
    "dataset_files = list(marqo_full_dir.iterdir())\n",
    "print(f\"Number of files in dataset dir: {len(dataset_files)}\")\n",
    "print(\"Files in dataset dir:\")\n",
    "pprint(sorted([file.name for file in dataset_files]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the dataset GitHub Repository we conclude that dataset structure is following:\n",
    "\n",
    "> 4 splits: training split with 80% of queries and 50% of documents, novel query splitwith the other 20% of queries and the same documents as the training split, novel corpus split with the same queries as the training split and unseen documents with the equal size of the training corpus, and zero-shot split with unseen queries and documents. <br><br>\n",
    "For each dataset such as marqo_gs_full_10m, there are 4 splits as discussed before. <br>\n",
    "    - **query_0_product_id_0** represents in-domain set, <br>\n",
    "    - **query_1_product_id_0** represents novel query set, <br>\n",
    "    - **query_0_product_id_1** represents novel document set, <br>\n",
    "    - **query_1_product_id_1** represents zero shot set, <br> <br>\n",
    "For each split, there is a ground truth csv containing triplet information, a set of validation ground truth and a set of test ground truth.\n",
    "\n",
    "This means that for our model we will be using only first, \"in-domain\" set.\n",
    "\n",
    "ðŸ”— ***Note:** Link to the original dataset [Github Repository](https://github.com/marqo-ai/GCL?tab=readme-ov-file).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `query_0_product_id_0.csv`: \n",
    "    - query (str),\n",
    "    - product_id (int), \n",
    "    - image_local (str),\n",
    "    - position (int),\n",
    "    - title (str),\n",
    "    - pair_id (str),\n",
    "    - score_linear (int),\n",
    "    - score_reciprocal (float),\n",
    "    - no_score (int),\n",
    "    - query_id (int)\n",
    "- `query_0_product_id_0_queries.json`: Dict[str, List[str]] **dev** and **test** keys with the list of queries (List[str])\n",
    "- `query_0_product_id_0_gt_dev.json`: Dict[str, Dict[str, int]] Queries as **keys** that inside have dictionaries with product IDs as a **keys** and a **values** are the rankings of the products.\n",
    "- `corpus_1/2.json`: List[Dict[str, Dict]] Product IDs as **keys** and values are dictionaries with **keys** and **values** same as columns in `query_0_product_id_0.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data samples: 3_926_764\n"
     ]
    }
   ],
   "source": [
    "test_path = marqo_full_dir / \"query_0_product_id_0.csv\"\n",
    "test_df = pd.read_csv(test_path)\n",
    "num_samples = len(test_df)\n",
    "print(f\"Number of data samples: {num_samples:_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clear row where title is smaller than query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 123_254 rows.\n"
     ]
    }
   ],
   "source": [
    "mask = test_df.apply(lambda row: len(row[\"title\"]) >= len(row[\"query\"]), axis=1)\n",
    "test_df = test_df[mask]\n",
    "print(f\"Removing {num_samples - mask.sum():_} rows.\")\n",
    "num_samples = len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking Queries that have minimum of 3 products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 2 rows.\n"
     ]
    }
   ],
   "source": [
    "test_df = test_df[test_df.groupby(by=\"query_id\")[\"query_id\"].transform(\"size\") >= 3]\n",
    "print(f\"Removing {num_samples - len(test_df):_} rows.\")\n",
    "num_samples = len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique queries: 78_586\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of unique queries: {test_df['query_id'].nunique():_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping unnecessary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.drop(columns=[\"image_local\", \"score_reciprocal\", \"no_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>product_id</th>\n",
       "      <th>position</th>\n",
       "      <th>title</th>\n",
       "      <th>pair_id</th>\n",
       "      <th>score_linear</th>\n",
       "      <th>query_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Earmuffs</td>\n",
       "      <td>11950591053179551937</td>\n",
       "      <td>2</td>\n",
       "      <td>La Carrie Faux Fur Headband with Stretch Women...</td>\n",
       "      <td>Earmuffs-11950591053179551937</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Earmuffs</td>\n",
       "      <td>13060356563414168615</td>\n",
       "      <td>3</td>\n",
       "      <td>Ugg Women's Shearling Earmuffs - Black</td>\n",
       "      <td>Earmuffs-13060356563414168615</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Earmuffs</td>\n",
       "      <td>6741082963333937131</td>\n",
       "      <td>5</td>\n",
       "      <td>Prettylittlething Women's Cream Soft Faux Fur ...</td>\n",
       "      <td>Earmuffs-6741082963333937131</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Earmuffs</td>\n",
       "      <td>8848678524883684053</td>\n",
       "      <td>8</td>\n",
       "      <td>Prettylittlething Women's Camel Soft Faux Fur ...</td>\n",
       "      <td>Earmuffs-8848678524883684053</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Earmuffs</td>\n",
       "      <td>11334298244441157208</td>\n",
       "      <td>12</td>\n",
       "      <td>Michael Michael Kors Women's Embellished Faux-...</td>\n",
       "      <td>Earmuffs-11334298244441157208</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      query            product_id  position  \\\n",
       "0  Earmuffs  11950591053179551937         2   \n",
       "1  Earmuffs  13060356563414168615         3   \n",
       "2  Earmuffs   6741082963333937131         5   \n",
       "3  Earmuffs   8848678524883684053         8   \n",
       "4  Earmuffs  11334298244441157208        12   \n",
       "\n",
       "                                               title  \\\n",
       "0  La Carrie Faux Fur Headband with Stretch Women...   \n",
       "1             Ugg Women's Shearling Earmuffs - Black   \n",
       "2  Prettylittlething Women's Cream Soft Faux Fur ...   \n",
       "3  Prettylittlething Women's Camel Soft Faux Fur ...   \n",
       "4  Michael Michael Kors Women's Embellished Faux-...   \n",
       "\n",
       "                         pair_id  score_linear  query_id  \n",
       "0  Earmuffs-11950591053179551937            99         0  \n",
       "1  Earmuffs-13060356563414168615            98         0  \n",
       "2   Earmuffs-6741082963333937131            96         0  \n",
       "3   Earmuffs-8848678524883684053            93         0  \n",
       "4  Earmuffs-11334298244441157208            89         0  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload to Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /Users/studeni/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "login(token=os.environ[\"HF_TOKEN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(df=test_df, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_id = \"Studeni/marqo-gs-dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0316fd53d3d45b3b12dbc2b19afd620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cb7ef4f5e02413d98c87f8d4601da1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1902 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82e6d4a72fe446568a080dd3af7d2085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1902 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/Studeni/marqo-gs-dataset/commit/fbc5d3a867ad3647ca4849428bf0ac2722f7db22', commit_message='Upload dataset', commit_description='', oid='fbc5d3a867ad3647ca4849428bf0ac2722f7db22', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.push_to_hub(repo_id=repo_id, split=\"train\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
