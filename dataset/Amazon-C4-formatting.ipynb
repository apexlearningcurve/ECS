{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = load_dataset(\"McAuley-Lab/Amazon-C4\", split=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets remove unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['qid', 'query', 'item_id', 'user_id', 'ori_rating', 'ori_review']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_test.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = ds_test.remove_columns(column_names=[\"user_id\", \"ori_rating\", \"ori_review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebee8b4cbd7a40e7a72fad693145e5d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c8650a1a054056b4f51ee16f96d302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/22 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/apexlearningcurve/c-4/commit/f080ae5afe28d07a5b256b33852c0d4066df6f27', commit_message='Upload dataset', commit_description='', oid='f080ae5afe28d07a5b256b33852c0d4066df6f27', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_test.push_to_hub(\"apexlearningcurve/c-4\", token=os.getenv(\"HF_TOKEN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = load_dataset(\n",
    "    \"McAuley-Lab/Amazon-C4\",\n",
    "    data_files=[\"sampled_item_metadata_1M.jsonl\"],\n",
    "    split=\"train\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['item_id', 'category', 'metadata']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train.column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if test examples are found in the train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qid': 0,\n",
       " 'query': \"I need filters that effectively trap dust and improve the air quality in my home. It's surprising how much dust they can collect in just a few months.\",\n",
       " 'item_id': 'B0C5QYYHTJ'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c30ba84d50fb4103a9f9a3911f0d059a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1058417 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'item_id': ['B0C5QYYHTJ'],\n",
       " 'category': ['Home'],\n",
       " 'metadata': ['Flintar Core 300 True HEPA Replacement Filters, Compatible with LEVOIT Core 300, Core 300S VortexAir Air Purifier, 3-in-1 H13 Grade True HEPA Filter Replacement, Core 300-RF, 2-Pack. Flintar Premium high-efficiency H13 Grade True HEPA Replacement Filter is made in Taiwan and is fully compatible with LEVOIT Core 300 and Core 300S VortexAir Air Purifier. This True HEPA Filtration System includes:   - Fine Pre-Filter: Traps larger particles in the air like dust, hairs, pet fur, lint, and more - H13 Grade True HEPA Filter: Captures 99.97% of harmful airborne particles down to 0.3 microns in size   - High-Efficiency Activated Carbon Filter: Absorbs household odors from pets, cooking, smoke, wildfire, and harmful VOCâ€™s Using Flintar premium high-efficiency air purifier filters and replacing the filters regularly will help optimize air cleaning performance. Replace your HEPA Filter every 6 months for optimal performance. Fully compatible with LEVOIT Cor 300 and Core 300S VortexAir Air Purifier.']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = ds_train.filter(lambda x: x[\"item_id\"] == ds_test[0][\"item_id\"])\n",
    "results.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we'll assume the rest are there as well for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the product categories (files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the c4 training dataset and save the item_ids only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds_train.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train[\"item_id\"].to_csv(\"./c4_item_ids.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load asin2category mapping table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./asin2category.json\", \"r\") as fp:\n",
    "    mapping_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the strucutre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('B07R3DYMH6', 'Home and Kitchen')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mapping_dict.items())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "c4_item_ids = pd.read_csv(\"./c4_item_ids.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a dict: \"category name\" : [list of item_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "c4_category2id = defaultdict(list)\n",
    "for _, item_id in c4_item_ids.values:\n",
    "    c4_category2id[mapping_dict[item_id]].append(item_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beauty and Personal Care</td>\n",
       "      <td>[B0778XR2QM, B07Q443QPB, B00CMGHTHC, B07NVH4C5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clothing Shoes and Jewelry</td>\n",
       "      <td>[B07NRD63N7, B07T589YKW, B07CZJNMYN, B01LPFSG1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patio Lawn and Garden</td>\n",
       "      <td>[B09655QKSN, B09DQ9BS43, B094XNG7CP, B07HFN7FV...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     category  \\\n",
       "0    Beauty and Personal Care   \n",
       "1  Clothing Shoes and Jewelry   \n",
       "2       Patio Lawn and Garden   \n",
       "\n",
       "                                                 ids  \n",
       "0  [B0778XR2QM, B07Q443QPB, B00CMGHTHC, B07NVH4C5...  \n",
       "1  [B07NRD63N7, B07T589YKW, B07CZJNMYN, B01LPFSG1...  \n",
       "2  [B09655QKSN, B09DQ9BS43, B094XNG7CP, B07HFN7FV...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(list(c4_category2id.items()), columns=[\"category\", \"ids\"])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./category2item_asin_ids.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch additional data for each item by category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run over all categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_directory(directory: Path):\n",
    "    if directory.exists() and directory.is_dir():\n",
    "        # Delete all contents of the directory\n",
    "        for item in directory.iterdir():\n",
    "            if item.is_dir():\n",
    "                shutil.rmtree(item)\n",
    "            else:\n",
    "                item.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beauty and Personal Care</td>\n",
       "      <td>['B0778XR2QM', 'B07Q443QPB', 'B00CMGHTHC', 'B0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clothing Shoes and Jewelry</td>\n",
       "      <td>['B07NRD63N7', 'B07T589YKW', 'B07CZJNMYN', 'B0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patio Lawn and Garden</td>\n",
       "      <td>['B09655QKSN', 'B09DQ9BS43', 'B094XNG7CP', 'B0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kindle Store</td>\n",
       "      <td>['B004Z1RFB2', 'B009RAOQ9A', 'B07K1F9RWY', 'B0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home and Kitchen</td>\n",
       "      <td>['B07JNQCMX7', 'B077SPV6JD', 'B09LKND673', 'B0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     category  \\\n",
       "0    Beauty and Personal Care   \n",
       "1  Clothing Shoes and Jewelry   \n",
       "2       Patio Lawn and Garden   \n",
       "3                Kindle Store   \n",
       "4            Home and Kitchen   \n",
       "\n",
       "                                                 ids  \n",
       "0  ['B0778XR2QM', 'B07Q443QPB', 'B00CMGHTHC', 'B0...  \n",
       "1  ['B07NRD63N7', 'B07T589YKW', 'B07CZJNMYN', 'B0...  \n",
       "2  ['B09655QKSN', 'B09DQ9BS43', 'B094XNG7CP', 'B0...  \n",
       "3  ['B004Z1RFB2', 'B009RAOQ9A', 'B07K1F9RWY', 'B0...  \n",
       "4  ['B07JNQCMX7', 'B077SPV6JD', 'B09LKND673', 'B0...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category2asin_ids_path = \"category2item_asin_ids.csv\"\n",
    "output_dir = \"c4-raw-meta\"\n",
    "cache_dir = \"cache\"\n",
    "df = pd.read_csv(category2asin_ids_path, index_col=[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove already processed categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_processed(df):\n",
    "    file_list = list(Path(output_dir).iterdir())\n",
    "    file_stems = [file.stem for file in file_list]\n",
    "    cleaned_file_names = [\n",
    "        file_stem[len(\"raw_meta_\") : -len(\"_c4\")].replace(\"_\", \" \")\n",
    "        for file_stem in file_stems\n",
    "    ]\n",
    "    return df[~df[\"category\"].isin(cleaned_file_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of all files: {len(df)}\")\n",
    "df = remove_processed(df)\n",
    "print(f\"Number of unprocessed files: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in tqdm(df.itertuples(), total=len(df)):\n",
    "    category_name = row.category.replace(\" \", \"_\")\n",
    "    dataset_name = f\"raw_meta_{category_name}\"\n",
    "\n",
    "    item_ids = ast.literal_eval(row.ids)\n",
    "    ds = load_dataset(\n",
    "        path=\"McAuley-Lab/Amazon-Reviews-2023\",\n",
    "        name=dataset_name,\n",
    "        trust_remote_code=True,\n",
    "        cache_dir=cache_dir,\n",
    "        split=\"full\",\n",
    "    )\n",
    "\n",
    "    # Use map to add a boolean column indicating whether the item_id is in the set\n",
    "    item_id_set = set(item_ids)  # Convert the list to a set for faster lookups\n",
    "    dataset = ds.map(lambda x: {\"is_in_set\": x[\"parent_asin\"] in item_id_set})\n",
    "\n",
    "    # Filter the dataset where the 'is_in_set' column is True\n",
    "    filtered_dataset = dataset.filter(lambda x: x[\"is_in_set\"])\n",
    "\n",
    "    # Optionally, remove the 'is_in_set' column if not needed\n",
    "    filtered_dataset = filtered_dataset.remove_columns(\"is_in_set\")\n",
    "\n",
    "    # Convert the filtered dataset to a pandas DataFrame (optional)\n",
    "    df_fitlered = filtered_dataset.to_pandas()\n",
    "\n",
    "    # Save to parquet\n",
    "    df_fitlered.to_parquet(f\"./{output_dir}/{dataset_name}_c4.parquet\")\n",
    "    clear_directory(Path(cache_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
