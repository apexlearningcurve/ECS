{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset, load_dataset\n",
    "from huggingface_hub import hf_hub_download\n",
    "from openai import OpenAI\n",
    "from prompts import BOOKS_PROMPT, QUERY_GENERATION_PROMPT\n",
    "from response_structure import ResponseStructure\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = Path(\"cache\")\n",
    "assert cache_dir.exists(), f\"Cache directory {cache_dir} does not exist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "648f6d1cf93d468580228202bc99f244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/1.16k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4db5e486a34415793b5dbc3d843967f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/3.85M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9abc83ec18cc4c34bb399720a3b4d90a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/20373 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data rows: 20373\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>queries_old</th>\n",
       "      <th>short_query</th>\n",
       "      <th>long_query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0007582471</td>\n",
       "      <td>[I'm looking for a modern makeover story that'...</td>\n",
       "      <td>One in a Million</td>\n",
       "      <td>One in a Million book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0060735880</td>\n",
       "      <td>[I need to find a unique history book that is ...</td>\n",
       "      <td>The Africa House</td>\n",
       "      <td>The Africa House by Christina Lamb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0061730793</td>\n",
       "      <td>[I'm looking for a book with beautiful words a...</td>\n",
       "      <td>Heart and Soul book</td>\n",
       "      <td>Heart and Soul by Kadir Nelson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0061900621</td>\n",
       "      <td>[I am looking for a book for my two-year-old w...</td>\n",
       "      <td>I'm a Big Sister</td>\n",
       "      <td>I'm a Big Sister book Joanna Cole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0062124277</td>\n",
       "      <td>[I'm looking for a great book, but I want to a...</td>\n",
       "      <td>Flight Behavior novel</td>\n",
       "      <td>Flight Behavior by Barbara Kingsolver</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id                                        queries_old  \\\n",
       "0  0007582471  [I'm looking for a modern makeover story that'...   \n",
       "1  0060735880  [I need to find a unique history book that is ...   \n",
       "2  0061730793  [I'm looking for a book with beautiful words a...   \n",
       "3  0061900621  [I am looking for a book for my two-year-old w...   \n",
       "4  0062124277  [I'm looking for a great book, but I want to a...   \n",
       "\n",
       "             short_query                             long_query  \n",
       "0       One in a Million                  One in a Million book  \n",
       "1       The Africa House     The Africa House by Christina Lamb  \n",
       "2    Heart and Soul book         Heart and Soul by Kadir Nelson  \n",
       "3       I'm a Big Sister      I'm a Big Sister book Joanna Cole  \n",
       "4  Flight Behavior novel  Flight Behavior by Barbara Kingsolver  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REPO_ID = \"apexlearningcurve/Amazon-Search-Benchmark\"\n",
    "df_queries = load_dataset(REPO_ID, split=\"test\", cache_dir=cache_dir).to_pandas()\n",
    "print(f\"Number of data rows: {len(df_queries)}\")\n",
    "df_queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique item ids: 20373\n"
     ]
    }
   ],
   "source": [
    "item_ids = df_queries[\"item_id\"].unique().tolist()\n",
    "print(f\"Number of unique item ids: {len(item_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform dataset to have uniqe item_id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>queries_old</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0007582471</td>\n",
       "      <td>[I'm looking for a modern makeover story that'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0060735880</td>\n",
       "      <td>[I need to find a unique history book that is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0061730793</td>\n",
       "      <td>[I'm looking for a book with beautiful words a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0061900621</td>\n",
       "      <td>[I am looking for a book for my two-year-old w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0062124277</td>\n",
       "      <td>[I'm looking for a great book, but I want to a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id                                        queries_old\n",
       "0  0007582471  [I'm looking for a modern makeover story that'...\n",
       "1  0060735880  [I need to find a unique history book that is ...\n",
       "2  0061730793  [I'm looking for a book with beautiful words a...\n",
       "3  0061900621  [I am looking for a book for my two-year-old w...\n",
       "4  0062124277  [I'm looking for a great book, but I want to a..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by item_id and aggregate the queries into a list\n",
    "df_queries = df_queries.groupby(\"item_id\").agg({\"query_old\": list}).reset_index()\n",
    "\n",
    "# Drop the query_id column (if it still exists, though grouping should remove it)\n",
    "df_queries = df_queries[[\"item_id\", \"query_old\"]]\n",
    "\n",
    "# Rename the columns for clarity if needed\n",
    "df_queries.columns = [\"item_id\", \"queries_old\"]\n",
    "\n",
    "df_queries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load product text for item ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = hf_hub_download(\n",
    "    repo_id=REPO_ID,\n",
    "    filename=\"sampled_item_metadata_1M_filtered.jsonl\",\n",
    "    repo_type=\"dataset\",\n",
    "    cache_dir=cache_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data rows: 1055136\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0007YMVOC</td>\n",
       "      <td>Warriors of Wrestling (The Biggest,Baddest,Mea...</td>\n",
       "      <td>The Biggest, meanest and bad wrestlers of all ...</td>\n",
       "      <td>Movies &amp; TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B004KPUHPE</td>\n",
       "      <td>Nowhere Boy</td>\n",
       "      <td>The story of former Beatle John Lennon's teen ...</td>\n",
       "      <td>Movies &amp; TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B0015OIFPC</td>\n",
       "      <td>Malos Habitos [Ntsc/region 1 &amp; 4 Dvd. Import-l...</td>\n",
       "      <td>La fe, el amor y la banidad son puestos a prue...</td>\n",
       "      <td>Movies &amp; TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00KG2QONE</td>\n",
       "      <td>House of Dust</td>\n",
       "      <td>A serial killer's ghost terrorizes a group of ...</td>\n",
       "      <td>Movies &amp; TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00AVSERBE</td>\n",
       "      <td>20 Country Love Songs Volume 2</td>\n",
       "      <td>This DVD compilation features 20 more classic ...</td>\n",
       "      <td>Movies &amp; TV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id                                              title  \\\n",
       "0  B0007YMVOC  Warriors of Wrestling (The Biggest,Baddest,Mea...   \n",
       "1  B004KPUHPE                                        Nowhere Boy   \n",
       "2  B0015OIFPC  Malos Habitos [Ntsc/region 1 & 4 Dvd. Import-l...   \n",
       "3  B00KG2QONE                                      House of Dust   \n",
       "4  B00AVSERBE                     20 Country Love Songs Volume 2   \n",
       "\n",
       "                                         description    file_name  \n",
       "0  The Biggest, meanest and bad wrestlers of all ...  Movies & TV  \n",
       "1  The story of former Beatle John Lennon's teen ...  Movies & TV  \n",
       "2  La fe, el amor y la banidad son puestos a prue...  Movies & TV  \n",
       "3  A serial killer's ghost terrorizes a group of ...  Movies & TV  \n",
       "4  This DVD compilation features 20 more classic ...  Movies & TV  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_products = pd.read_json(filepath, lines=True)\n",
    "print(f\"Number of data rows: {len(df_products)}\")\n",
    "df_products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean non-existing item_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20463\n",
      "20373\n"
     ]
    }
   ],
   "source": [
    "print(len(item_ids))\n",
    "item_ids = set(df_products[\"item_id\"].tolist()).intersection(set(item_ids))\n",
    "print(len(item_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_queries = df_queries[df_queries[\"item_id\"].apply(lambda x: x in item_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### push to hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_queries = Dataset.from_pandas(df=df_queries, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_queries.push_to_hub(repo_id=REPO_ID, split=\"test\", commit_message=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract product text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_text(row) -> str:\n",
    "    title = row[\"title\"]\n",
    "    description = row[\"description\"]\n",
    "    category = \"Product category:\" + row[\"file_name\"]\n",
    "    text = \"\\n\".join([title, description, category])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>file_name</th>\n",
       "      <th>product_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>B0B8JXDS86</td>\n",
       "      <td>A Man Called Otto</td>\n",
       "      <td>A grumpy widower forms an unlikely friendship ...</td>\n",
       "      <td>Movies &amp; TV</td>\n",
       "      <td>A Man Called Otto\\nA grumpy widower forms an u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>B089CZYTLL</td>\n",
       "      <td>Frasier: The Complete Series</td>\n",
       "      <td>Psychiatrist and \"Cheers\" regular Dr. Frasier ...</td>\n",
       "      <td>Movies &amp; TV</td>\n",
       "      <td>Frasier: The Complete Series\\nPsychiatrist and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>B09RF1PGLJ</td>\n",
       "      <td>Everything Everywhere All At Once</td>\n",
       "      <td>Academy Award winning Best Picture starring Ac...</td>\n",
       "      <td>Movies &amp; TV</td>\n",
       "      <td>Everything Everywhere All At Once\\nAcademy Awa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>B00111YM60</td>\n",
       "      <td>30 Days Of Night</td>\n",
       "      <td>Product Description\\nJosh Hartnett (The Black ...</td>\n",
       "      <td>Movies &amp; TV</td>\n",
       "      <td>30 Days Of Night\\nProduct Description\\nJosh Ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>B01IWQUTY0</td>\n",
       "      <td>Deadbeat</td>\n",
       "      <td>Kevin \"Pac\" Pacalioglu (Tyler Labine) is a laz...</td>\n",
       "      <td>Movies &amp; TV</td>\n",
       "      <td>Deadbeat\\nKevin \"Pac\" Pacalioglu (Tyler Labine...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id                              title  \\\n",
       "17   B0B8JXDS86                  A Man Called Otto   \n",
       "24   B089CZYTLL       Frasier: The Complete Series   \n",
       "55   B09RF1PGLJ  Everything Everywhere All At Once   \n",
       "110  B00111YM60                   30 Days Of Night   \n",
       "126  B01IWQUTY0                           Deadbeat   \n",
       "\n",
       "                                           description    file_name  \\\n",
       "17   A grumpy widower forms an unlikely friendship ...  Movies & TV   \n",
       "24   Psychiatrist and \"Cheers\" regular Dr. Frasier ...  Movies & TV   \n",
       "55   Academy Award winning Best Picture starring Ac...  Movies & TV   \n",
       "110  Product Description\\nJosh Hartnett (The Black ...  Movies & TV   \n",
       "126  Kevin \"Pac\" Pacalioglu (Tyler Labine) is a laz...  Movies & TV   \n",
       "\n",
       "                                          product_text  \n",
       "17   A Man Called Otto\\nA grumpy widower forms an u...  \n",
       "24   Frasier: The Complete Series\\nPsychiatrist and...  \n",
       "55   Everything Everywhere All At Once\\nAcademy Awa...  \n",
       "110  30 Days Of Night\\nProduct Description\\nJosh Ha...  \n",
       "126  Deadbeat\\nKevin \"Pac\" Pacalioglu (Tyler Labine...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jobs = df_products[df_products[\"item_id\"].isin(item_ids)].copy()\n",
    "df_jobs[\"product_text\"] = df_jobs.apply(get_product_text, axis=1)\n",
    "df_jobs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with Chat Completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_queries(\n",
    "    prompt: str, product_text: str, model: str = \"gpt-4o-mini\", temperature: float = 0\n",
    ") -> str:\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        response_format=ResponseStructure,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt},\n",
    "            {\"role\": \"user\", \"content\": product_text},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Timberland Shelburne Three Piece Hardside Set, Chocolate Truffle\\nPolyvinyl Chloride free, expandable, hard side three piece luggage set\\nProduct category:Clothing Shoes & Jewelry'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_product = df_products.iloc[random.randint(0, len(df_products))]\n",
    "product_text = get_product_text(random_product)\n",
    "product_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_queries(prompt=QUERY_GENERATION_PROMPT, product_text=product_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'long_query': 'Expandable three piece hardside luggage set',\n",
      " 'reasoning': 'The Timberland Shelburne Three Piece Hardside Set is designed '\n",
      "              'for travelers seeking durable and stylish luggage. Its hard '\n",
      "              'side construction offers protection for belongings, while the '\n",
      "              'expandable feature provides extra packing space. The chocolate '\n",
      "              'truffle color adds a touch of elegance, making it suitable for '\n",
      "              'various travel occasions.',\n",
      " 'short_query': 'Hardside luggage set'}\n"
     ]
    }
   ],
   "source": [
    "pprint(response.model_dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'long_query': 'Greatest wrestlers DVD set collection',\n",
      " 'reasoning': 'This product is a collection of wrestling matches featuring '\n",
      "              'some of the most famous and formidable wrestlers, packaged in a '\n",
      "              '4 DVD set. It highlights intense competition and showcases '\n",
      "              'legendary figures in wrestling history, making it appealing to '\n",
      "              'fans of the sport.',\n",
      " 'short_query': 'Wrestling DVD collection'}\n",
      "--------------------------------------------------------------------------------\n",
      "{'long_query': 'Nowhere Boy movie about John Lennon',\n",
      " 'reasoning': 'The product is a movie that dramatizes the early life of John '\n",
      "              'Lennon, focusing on his relationships with his aunt and mother. '\n",
      "              'It is a biographical film that appeals to fans of The Beatles '\n",
      "              'and those interested in music history.',\n",
      " 'short_query': 'Nowhere Boy'}\n",
      "--------------------------------------------------------------------------------\n",
      "{'long_query': 'Malos Habitos NTSC DVD import movie',\n",
      " 'reasoning': \"The product is a DVD of the movie 'Malos Habitos', which \"\n",
      "              'explores themes of faith, love, and the impact of eating habits '\n",
      "              'on the lives of three women. It is an import DVD suitable for '\n",
      "              'NTSC regions 1 and 4, indicating its specific compatibility for '\n",
      "              'certain regions. This information is essential for users '\n",
      "              'searching for this particular film.',\n",
      " 'short_query': 'Malos Habitos DVD'}\n",
      "--------------------------------------------------------------------------------\n",
      "{'long_query': 'House of Dust horror movie streaming',\n",
      " 'reasoning': 'The product is a horror movie that revolves around a ghost of a '\n",
      "              'serial killer haunting college students after his ashes are '\n",
      "              'released. The film features notable actors and fits within the '\n",
      "              'horror genre, appealing to fans of supernatural thrillers.',\n",
      " 'short_query': 'House of Dust'}\n",
      "--------------------------------------------------------------------------------\n",
      "{'long_query': 'classic country love songs DVD compilation',\n",
      " 'reasoning': 'This product is a DVD compilation of classic country love songs '\n",
      "              'performed live, featuring well-known artists. It appeals to '\n",
      "              'fans of country music and those looking for nostalgic '\n",
      "              'performances.',\n",
      " 'short_query': 'country love songs DVD'}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Testing on a few examples\n",
    "for _, row in df_products[:5].iterrows():\n",
    "    product_text = get_product_text(row)\n",
    "    result = get_queries(prompt=QUERY_GENERATION_PROMPT, product_text=product_text)\n",
    "    pprint(result.model_dump())\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Batch Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_by_item_id(item_id: str) -> str:\n",
    "    product = df_products[df_products[\"item_id\"] == item_id].iloc[0]\n",
    "    product_text = get_product_text(product)\n",
    "    return product_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.lib._parsing import _completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'json_schema',\n",
       " 'json_schema': {'schema': {'properties': {'reasoning': {'title': 'Reasoning',\n",
       "     'type': 'string'},\n",
       "    'short_query': {'title': 'Short Query', 'type': 'string'},\n",
       "    'long_query': {'title': 'Long Query', 'type': 'string'}},\n",
       "   'required': ['reasoning', 'short_query', 'long_query'],\n",
       "   'title': 'ResponseStructure',\n",
       "   'type': 'object',\n",
       "   'additionalProperties': False},\n",
       "  'name': 'ResponseStructure',\n",
       "  'strict': True}}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_completions.type_to_response_format_param(ResponseStructure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20373"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ae06f71e1294c7a99a52d6b60b79ec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating tasks:   0%|          | 0/20373 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tasks = []\n",
    "\n",
    "for row in tqdm(df_jobs.itertuples(), total=len(df_jobs), desc=\"Generating tasks\"):\n",
    "    prompt = QUERY_GENERATION_PROMPT\n",
    "    if row.file_name == \"Books\":\n",
    "        prompt += f\"\\n{BOOKS_PROMPT}\"\n",
    "\n",
    "    task = {\n",
    "        \"custom_id\": row.item_id,\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            # This is what you would have in your Chat Completions API call\n",
    "            # \"model\": \"gpt-4o-mini\",\n",
    "            \"model\": \"gpt-4o-2024-08-06\",\n",
    "            \"temperature\": 0,\n",
    "            \"response_format\": _completions.type_to_response_format_param(\n",
    "                ResponseStructure\n",
    "            ),\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": prompt},\n",
    "                {\"role\": \"user\", \"content\": row.product_text},\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "\n",
    "    tasks.append(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save as jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = Path(\"artifacts/batch_tasks_queries_v5.jsonl\")\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for obj in tasks:\n",
    "        f.write(json.dumps(obj) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_file = client.files.create(file=open(output_file, \"rb\"), purpose=\"batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-8Mydv3p7Y2cVha6DiD4yHqzf', bytes=60706895, created_at=1727106157, filename='batch_tasks_queries_v5.jsonl', object='file', purpose='batch', status='processed', status_details=None)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the batch job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_job = client.batches.create(\n",
    "    input_file_id=batch_file.id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking batch status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "BatchRequestCounts(completed=20373, failed=0, total=20373)\n"
     ]
    }
   ],
   "source": [
    "batch_job = client.batches.retrieve(batch_job.id)\n",
    "print(batch_job.status)\n",
    "print(batch_job.request_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file_id = batch_job.output_file_id\n",
    "result = client.files.content(result_file_id).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_results = Path(\"artifacts/batch_tasks_queries_results_v5.jsonl\")\n",
    "\n",
    "with open(output_file_results, \"wb\") as file:\n",
    "    file.write(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data from saved file\n",
    "results = []\n",
    "with open(output_file_results, \"r\") as file:\n",
    "    for line in file:\n",
    "        # Parsing the JSON string into a dict and appending to the list of results\n",
    "        json_object = json.loads(line.strip())\n",
    "        results.append(json_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item ID: B0B8JXDS86\n",
      "Product Text: \"A Man Called Otto\\nA grumpy widower forms an unlikely friendship with his new neighbors that turns his world around.\\nProduct category:Movies & TV\"\n",
      "{'reasoning': \"The product is a movie titled 'A Man Called Otto', which is about a grumpy widower who forms an unexpected friendship with his neighbors. This film likely falls under the drama or comedy-drama genre, focusing on themes of friendship and personal transformation. When generating search queries, it's important to highlight the movie's title and its category to ensure users can find it easily.\", 'short_query': 'A Man Called Otto', 'long_query': 'A Man Called Otto movie'}\n",
      "--------------------------------------------------------------------------------\n",
      "Item ID: B089CZYTLL\n",
      "Product Text: \"Frasier: The Complete Series\\nPsychiatrist and \\\"Cheers\\\" regular Dr. Frasier Crane (Kelsey Grammer) left Boston for his hometown of Seattle and a job as a radio call-in show host, in this hit 1993-2004 spin-off. Thanks to brother Niles (David Hyde Pierce), dad Martin (John Mahoney), health care worker Daphne (Jane Leeves), and radio producer Roz (Peri Gilpin), though, things were just as aggravating on the West Coast.258 episodes on 44 discs. 98 1/4 hrs. Standard; Soundtrack: English Dolby Digital stereo.\\nProduct category:Movies & TV\"\n",
      "{'reasoning': \"This product is a complete series box set of the TV show 'Frasier,' which is a spin-off of 'Cheers.' It includes all episodes from the series, featuring the main character Dr. Frasier Crane and his interactions with family and colleagues. The set is aimed at fans of the show or those interested in classic sitcoms, offering a comprehensive collection of the series on multiple discs.\", 'short_query': 'Frasier complete series', 'long_query': 'Frasier complete series box set'}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Reading only the first results\n",
    "for res in results[:2]:\n",
    "    item_id = res[\"custom_id\"]\n",
    "    result = json.loads(res[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"])\n",
    "    product_text = get_product_by_item_id(item_id)\n",
    "    print(f\"Item ID: {item_id}\")\n",
    "    print(f\"Product Text: {json.dumps(product_text, indent=2)}\")\n",
    "    print(result)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_queries[\"short_query\"] = \"\"\n",
    "df_queries[\"long_query\"] = \"\"\n",
    "\n",
    "for res in results:\n",
    "    item_id = res[\"custom_id\"]\n",
    "    result = json.loads(res[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"])\n",
    "    response = ResponseStructure.model_validate(result)\n",
    "\n",
    "    df_queries.loc[\n",
    "        df_queries[\"item_id\"] == item_id,\n",
    "        [\n",
    "            \"long_query\",\n",
    "            \"short_query\",\n",
    "        ],\n",
    "    ] = [\n",
    "        response.long_query,\n",
    "        response.short_query,\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_queries.to_parquet(\n",
    "    \"artifacts/test_with_gpt-4o_generated_queries.parquet\", index=False\n",
    ")\n",
    "ds_queries = Dataset.from_pandas(df=df_queries, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_queries.push_to_hub(repo_id=REPO_ID, split=\"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
