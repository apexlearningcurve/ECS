{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from gpt_reranker import run_reranker\n",
    "from openai import OpenAI\n",
    "from prompts import AMAZON_RANKING_PROMPT\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, QuantoConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT Reranker - Cross Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_text = \"\"\"\n",
    "YMIX Macbook Pro 13\" Case Non-Retina,Folio Embroidered Shell Plastic Hard Protective Cover for Old MacBook Pro 13 Inch with CD-ROM Drive,Model A1278(A_Embroidered Floral)\n",
    "\n",
    "product category: Electronics\n",
    "\"\"\"\n",
    "query = \"case for apple laptop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-24 13:57:57.629\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mgpt_reranker\u001b[0m:\u001b[36mrun_reranker\u001b[0m:\u001b[36m76\u001b[0m - \u001b[32m\u001b[1mLabel: Yes with Probability: 0.9999722707254635\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "label, probab = run_reranker(\n",
    "    client=client,\n",
    "    prompt=AMAZON_RANKING_PROMPT,\n",
    "    query=query,\n",
    "    product_text=product_text,\n",
    "    logger_level=\"SUCCESS\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OS - Cross Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "# MODEL_ID = \"google/gemma-2-2b-it\"\n",
    "cache_dir = Path(\"../cache\")\n",
    "assert cache_dir.exists(), f\"Cache directory {cache_dir} does not exist\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemma 2 2B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d55f8278d9a146b8ac6610fb57e86596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, cache_dir=cache_dir)\n",
    "quantized_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    cache_dir=cache_dir,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llama 3.1 8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b45ff3df9bd74722a32a571eb4a191b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58bfc700084d4729a787b574724d3017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af4ef61e9b49489fa8dd0aa83c6a76e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "592782978e2b4a0fa014c9fd5d03f392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e3143f62bd4e78bb6aec371d2ddeb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "968a609a670a4773ab2c5d04eb753f70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0946c5bff7514c14b8e0d129140582b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0da29d0c63ba46beb9f0288f67ecc833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc78f775eb574cda83700480cb9b2e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "836b8e7fb04e48589fea9029e108f6ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd74b96723684336a5804a384251fdf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31437339ad504aa7b800960f7a2de92d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, cache_dir=cache_dir)\n",
    "quantization_config = QuantoConfig(weights=\"int8\")\n",
    "quantized_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID, quantization_config=quantization_config, cache_dir=cache_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>\n",
      "You are an Assistant responsible for helping detect whether the retrieved product is relevant to the query. For a given input, you need to output a single token: \"Yes\" or \"No\" indicating the retrieved product is relevant to the query.\n",
      "\n",
      "Query: Younique setting powder\n",
      "Product: \n",
      "\"\"\"\n",
      "Younique Touch Behold Translucent Setting Powder\n",
      "\n",
      "Touch Behold Translucent Setting Powder. Younique’s Touch Behold Translucent Setting Powder effortlessly locks and loads your look so you’re ready to take on the world. Use as the finishing touch to help keep makeup in place, or wear directly on skin for a softening, matte look.\n",
      "\n",
      "product category: Beauty & Personal Care\n",
      "\"\"\"\n",
      "Relevant: Yes\n",
      "\n",
      "Query: white musk hand cream\n",
      "Product: \n",
      "\"\"\"\n",
      "Braided Hair Clips for Women Girls, Sparkling Crystal Stone Braided Hair Clips Barrette with 3 Small Clips, Triple Hair Clips with Rhinestones for Sectioning,4PCS (4pcs-Type A)\n",
      "\n",
      "product category: Beauty & Personal Care\n",
      "\"\"\"\n",
      "Relevant: No\n",
      "\n",
      "Query: HP Pavilion dm4 replacement battery\n",
      "Product: \n",
      "\"\"\"\n",
      "ATC 11.1V 6-Cell Replacement Laptop Battery for HP Pavilion dm4-1062nr Pavilion dm4-1063cl Pavilion dm4-1063he Pavilion dm4-1065dx Pavilion dm4-1070ee Pavilion dm4-1070ef\n",
      "\n",
      "product category: Electronics\n",
      "\"\"\"\n",
      "Relevant: Yes\n",
      "\n",
      "Query: Cushionaire cork sandals\n",
      "Product: \n",
      "\"\"\"\n",
      "CUSHIONAIRE Women's Lane Cozy Cork footbed Sandal with Faux fur lining and +Comfort\n",
      "\n",
      "Women's Cushionaire comfort Cork footbed sandal with Faux Fur lining. Stay cool with comfy sandals that will give you comfort throughout your day.\n",
      "\n",
      "product category: Clothing Shoes & Jewelry\n",
      "\"\"\"\n",
      "Relevant: Yes\n",
      "\n",
      "Query: under cabinet LED light\n",
      "Product: \n",
      "\"\"\"\n",
      "Christmas Snowflake Projector Lights Outdoor Led Snowfall Show with Remote Control Waterproof Landscape Decorative Lighting for Christmas Holiday Party Wedding Garden Patio\n",
      "\n",
      "product category: Tools & Home Improvement\n",
      "\"\"\"\n",
      "Relevant: No \n",
      "\n",
      "Query: macbook keyboard\n",
      "Product: \n",
      "\"\"\"\n",
      "\n",
      "YMIX Macbook Pro 13\" Case Non-Retina,Folio Embroidered Shell Plastic Hard Protective Cover for Old MacBook Pro 13 Inch with CD-ROM Drive,Model A1278(A_Embroidered Floral)\n",
      "\n",
      "product category: Electronics\n",
      "\n",
      "\"\"\"\n",
      "Relevant: \n",
      "The input consists of two\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(\n",
    "    ECOMMERCE_RANKING_PROMPT.format(\n",
    "        query=\"macbook keyboard\", product_text=product_text\n",
    "    ),\n",
    "    return_tensors=\"pt\",\n",
    ").to(quantized_model.device)\n",
    "\n",
    "outputs = quantized_model.generate(**input_ids, max_new_tokens=5)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = tokenizer.encode(\n",
    "    ECOMMERCE_RANKING_PROMPT.format(\n",
    "        query=\"macbook keyboard\", product_text=product_text\n",
    "    ),\n",
    "    return_tensors=\"pt\",\n",
    ").to(quantized_model.device)\n",
    "\n",
    "output = quantized_model.forward(input_tensor)\n",
    "logits = output.logits[0, -1]  # from first batch take last token logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID for Yes: 9642, No: 2822\n"
     ]
    }
   ],
   "source": [
    "yes_token_id = tokenizer.convert_tokens_to_ids(\"Yes\")\n",
    "no_token_id = tokenizer.convert_tokens_to_ids(\"No\")\n",
    "print(f\"ID for Yes: {yes_token_id}, No: {no_token_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability for Yes: 0.05030212178826332\n",
      "Probability for No: 0.08026696741580963\n"
     ]
    }
   ],
   "source": [
    "print(f\"Probability for Yes: {torch.softmax(logits, dim=-1)[yes_token_id]}\")\n",
    "print(f\"Probability for No: {torch.softmax(logits, dim=-1)[no_token_id]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability for Yes: 0.668552815914154\n",
      "Probability for No: 0.09124583750963211\n"
     ]
    }
   ],
   "source": [
    "print(f\"Probability for Yes: {torch.softmax(logits, dim=-1)[yes_token_id]}\")\n",
    "print(f\"Probability for No: {torch.softmax(logits, dim=-1)[no_token_id]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
